{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import os\n",
    "from urllib.request import Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "citiesurl = []\n",
    "for i in range(0,1040,20):\n",
    "    cityurl = 'https://www.tripadvisor.in/Hotels-g293860-oa' + str(i) + '-India-Hotels.html'\n",
    "    citiesurl.append(cityurl)\n",
    "CityLink =[]\n",
    "for theurls in citiesurl:\n",
    "    thepage = urllib.request.urlopen(theurls)\n",
    "    soup = BeautifulSoup(thepage, \"lxml\")\n",
    "    cities = soup.findAll(\"div\", {\"class\":\"geo_name\"})\n",
    "    for i in range(len(cities)):\n",
    "        city = cities[i]\n",
    "        citylink = 'https://www.tripadvisor.in'+ city.a['href']\n",
    "        CityLink.append(citylink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are trying to extract all the city links by using a for loop for the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(len(CityLink)):\n",
    "    thepages = urllib.request.urlopen(CityLink[i])\n",
    "\n",
    "    soup = BeautifulSoup(thepages, \"lxml\")\n",
    "\n",
    "    hotels = soup.findAll(\"span\",{\"class\":\"count\"})\n",
    "\n",
    "    leng = hotels[0].text.strip()\n",
    "\n",
    "    l.append(leng)\n",
    "    \n",
    "#here we are appending the no. of hotels in a particular area\n",
    "\n",
    "k = []\n",
    "for le in l:\n",
    "    if len(le) == 6:\n",
    "        hotel_no = int(le[1:5])\n",
    "    elif len(le) == 5:\n",
    "        hotel_no = int(le[1:4])\n",
    "    elif len(le) == 4:\n",
    "        hotel_no = int(le[1:3])\n",
    "    elif len(le) == 3:\n",
    "        hotel_no = int(le[1:2])\n",
    "    k.append(hotel_no)\n",
    "\n",
    "#now as the no. of hotels are in str form so we need to convert them to int to use them further.\n",
    "\n",
    "data_ids = []\n",
    "for i in range(len(CityLink)):\n",
    "    initialurl = CityLink[i]\n",
    "    thepages = urllib.request.urlopen(initialurl)\n",
    "    soup = BeautifulSoup(thepages, \"lxml\")\n",
    "    no_of_hotels = soup.findAll(\"div\",{\"class\":\"global-nav-geopill\"})\n",
    "    for tag in soup.find_all(class_=\"global-nav-geopill\") :\n",
    "        asf = tag.attrs\n",
    "        data_id = asf['data-id']\n",
    "    data_ids.append(data_id) \n",
    "    \n",
    "#Here we are extracting the data ids of all the cities using their link.\n",
    "    \n",
    "urlb = []\n",
    "for i in range(0,len(CityLink)):\n",
    "    R = k[i]%30\n",
    "    e = 35 +len(data_ids[i])\n",
    "    ulse = []\n",
    "    ulso = []\n",
    "    if R ==0:\n",
    "        for j in range(0,k[i],30):\n",
    "            uls = CityLink[i][0:35]+data_ids[i] + '-oa'+ str(j) + CityLink[i][e:len(CityLink[i])]\n",
    "            ulse.append(uls)\n",
    "        urlb.append(ulse)    \n",
    "    else:\n",
    "        for j in range(0,k[i]+R,30):\n",
    "            uls = CityLink[i][0:35]+data_ids[i] + '-oa'+ str(j) + CityLink[i][e:len(CityLink[i])]\n",
    "            ulso.append(uls)\n",
    "    \n",
    "        urlb.append(ulso)\n",
    "        \n",
    "Url_s = []\n",
    "for i in urlb:\n",
    "    for e in i:\n",
    "        Url_s.append(e)\n",
    "        \n",
    "#Here we have successfully appended all the pages links on a particular city link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, requests\n",
    "from bs4 import BeautifulSoup\n",
    "ll_hotels = []\n",
    "for ul in urlb[0]: \n",
    "    headers = {'connection':'Keep-Alive','accept-language':'en-GB,en-US;q=0.8,en;q=0.6',  'accept-encoding':'gzip,deflate,br','accept':'text/html, */*','accept-charset':'GBK,utf-8;q=0.7,*;q=0.3','cache-control':'max-age=0','origin':'https://www.tripadvisor.in','referer':'https://www.tripadvisor.in/Hotels-g304551-New_Delhi_National_Capital_Territory_of_Delhi-Hotels.html','user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36','X-Requested-With':'XMLHttpRequest','X-Puid':'Wfn9PAokHnoAASMvODsAAAGI','host':'www.tripadvisor.in','content-type':'application/x-www-form-urlencoded; charset=UTF-8','content-length':'77'}\n",
    "    \n",
    "    request_timeout_parameter = 30\n",
    "    data = {'plSeed':497756756,'showSnippets':'false','sortOrder':'popularity','reqNum':1,'changeSet':'MAIN_META'}\n",
    "    response = requests.post(ul, headers = headers,data = data, timeout = request_timeout_parameter, allow_redirects=True)\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    hotel_url = soup.findAll(\"div\" , {\"class\":\"listing_title\"})\n",
    "    lk_hotels = []\n",
    "    for i in range(len(hotel_url)):\n",
    "        hotel_link = 'https://www.tripadvisor.in' + hotel_url[i].a['href']\n",
    "        lk_hotels.append(hotel_link)\n",
    "    ll_hotels.append(lk_hotels)\n",
    "    \n",
    "hotelurl = []\n",
    "for i in ll_hotels:\n",
    "    for e in i:\n",
    "        hotelurl.append(e)\n",
    "        \n",
    "hotel_url = set(hotelurl)\n",
    "\n",
    "\n",
    "#Here we are extracting all the links of the hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
